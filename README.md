# ğŸ“Š Job Market Analytics Dashboard

An end-to-end **ETL + Analytics + Dashboard** project that extracts job postings, transforms and stores them in a database, applies **NLP to extract skills**, and visualizes insights in an interactive **Streamlit dashboard**.

---

## ğŸš€ Features
- ğŸ”„ **ETL Pipeline**: Extract â†’ Transform â†’ Load jobs data into SQLite DB.  
- ğŸ§¹ **Data Cleaning**: Preprocessing of job descriptions.  
- ğŸ›  **Skill Extraction (NLP)**: Identify top skills (e.g., Python, SQL, Excel) from job descriptions.  
- ğŸ“ˆ **Interactive Dashboard**: Explore job trends, skills in demand, and more using **Streamlit + Plotly**.  
- ğŸ’¾ **Database Storage**: All jobs stored in `data/jobs.db` (SQLite).  
- ğŸ“Š **Reports**: Export filtered jobs into Excel for offline use.  

---

## ğŸ–¼ï¸ Dashboard Preview  

### ğŸ”¹ ETL Status & Controls  
![ETL and Controls](images/etl_controls.png)

### ğŸ”¹ Job Trends Over Time  
![Job Trends](images/job_trends.png)

### ğŸ”¹ Top 10 Skills in Demand (NLP Extracted)  
![Skills in Demand](images/skills_in_demand.png)

---

## ğŸ—‚ï¸ Project Structure

job-market-analytics-starter/
â”‚â”€â”€ data/ # SQLite DB (jobs.db) & raw data
â”‚â”€â”€ exports/ # Exported reports
â”‚â”€â”€ reports/ # ETL/analytics reports
â”‚â”€â”€ sample_data/ # Sample JSON data
â”‚â”€â”€ src/ # ETL & NLP logic
â”‚â”€â”€ taxonomy/ # Skills taxonomy for NLP
â”‚â”€â”€ streamlit_app.py # Dashboard app
â”‚â”€â”€ run_pipeline.py # Orchestrates ETL pipeline
â”‚â”€â”€ run_etl.py # Run ETL manually
â”‚â”€â”€ run.py # Utility runner
â”‚â”€â”€ requirements.txt # Python dependencies
â”‚â”€â”€ jobs.db # SQLite database
â”‚â”€â”€ filtered_jobs.xlsx # Example exported report
â”‚â”€â”€ images/ # Screenshots for README


---

## âš™ï¸ Installation & Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/job-market-analytics-starter.git
   cd job-market-analytics-starter
2.Create virtual environment
Copy code
python -m venv venv
venv\Scripts\activate   # On Windows
source venv/bin/activate  # On Mac/Linux
Install dependencies


3.Copy code
pip install -r requirements.txt
Run ETL pipeline

4.Copy code
python run_pipeline.py
This will create/update the SQLite database: data/jobs.db.

5.Start Dashboard
Copy code
streamlit run streamlit_app.py

ğŸ“Š Dashboard Features

âœ… Job Trends over Time

âœ… Top Skills in Demand (NLP Extracted)

âœ… Export Filtered Jobs to Excel

âœ… Interactive Visuals with Plotly

## ğŸ›  Tech Stack
- **Python 3.10+**
- **Streamlit** â€“ Dashboard UI
- **Plotly** â€“ Data Visualization
- **SQLite** â€“ Database
- **pandas / numpy** â€“ Data Processing
- **spaCy / NLP** â€“ Skills Extraction
- **FastAPI** â€“ REST API to serve job & skills data


ğŸ™Œ Future Enhancements

ğŸ”¹ Job posting API integration (live data)

ğŸ”¹ Advanced NLP for more accurate skill extraction

ğŸ”¹ ML-based forecasting of job demand

ğŸ”¹ Deployment on Streamlit Cloud / AWS / Azure

ğŸ¤ Contribution

Want to add new features?

Fork the repo

Create a feature branch

Submit a PR ğŸš€
